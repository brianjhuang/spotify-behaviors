{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampled_users_100000.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_fp = os.path.join(\"sampled_users_100000.csv\")\n",
    "spark_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(spark_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_path_one = os.path.join(\"data\", \"track_features\", \"tf_000000000000.csv\")\n",
    "tf_path_two = os.path.join(\"data\", \"track_features\", \"tf_000000000000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_one = pd.read_csv(tf_path_one)\n",
    "track_features_two = pd.read_csv(tf_path_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features = pd.concat([track_features_one, track_features_two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userFeatures = pd.merge(users, track_features, left_on = 'track_id_clean', right_on = 'track_id')\n",
    "nonModifiedFeatures = pd.merge(users, track_features, left_on = 'track_id_clean', right_on = 'track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_position</th>\n",
       "      <th>session_length</th>\n",
       "      <th>track_id_clean</th>\n",
       "      <th>skip_1</th>\n",
       "      <th>skip_2</th>\n",
       "      <th>skip_3</th>\n",
       "      <th>not_skipped</th>\n",
       "      <th>context_switch</th>\n",
       "      <th>no_pause_before_play</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>acoustic_vector_0</th>\n",
       "      <th>acoustic_vector_1</th>\n",
       "      <th>acoustic_vector_2</th>\n",
       "      <th>acoustic_vector_3</th>\n",
       "      <th>acoustic_vector_4</th>\n",
       "      <th>acoustic_vector_5</th>\n",
       "      <th>acoustic_vector_6</th>\n",
       "      <th>acoustic_vector_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_459c8917-3a1b-45b1-8c26-4dc86b179948</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>t_d5216514-209f-4ea2-9046-bb8efc8c7a2c</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.593578</td>\n",
       "      <td>0.076202</td>\n",
       "      <td>0.158479</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>-0.408168</td>\n",
       "      <td>0.50601</td>\n",
       "      <td>0.202745</td>\n",
       "      <td>-0.514325</td>\n",
       "      <td>-0.497011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                session_id session_position session_length  \\\n",
       "0  30_459c8917-3a1b-45b1-8c26-4dc86b179948                3             16   \n",
       "\n",
       "                           track_id_clean skip_1 skip_2 skip_3 not_skipped  \\\n",
       "0  t_d5216514-209f-4ea2-9046-bb8efc8c7a2c  false  false   true       false   \n",
       "\n",
       "  context_switch no_pause_before_play  ... time_signature   valence  \\\n",
       "0              0                    1  ...              4  0.593578   \n",
       "\n",
       "  acoustic_vector_0 acoustic_vector_1 acoustic_vector_2 acoustic_vector_3  \\\n",
       "0          0.076202          0.158479          0.005198         -0.408168   \n",
       "\n",
       "  acoustic_vector_4 acoustic_vector_5 acoustic_vector_6 acoustic_vector_7  \n",
       "0           0.50601          0.202745         -0.514325         -0.497011  \n",
       "\n",
       "[1 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userFeatures.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(userFeatures.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = cols[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "userFeatures.drop(columns = drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "userFeatures['mode'] = userFeatures['mode'].apply(lambda x: 1 if x == 'major' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = userFeatures.groupby('session_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.reset_index().drop('session_id', axis = 1)\n",
    "#we wanted to groupby so we would cluster by user avg song features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop our code so we only have the track features for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "cluster = KMeans(n_clusters = 3)\n",
    "cluster.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grab our cluster labels and re-add them to our features so we have session_id and corresponding cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = userFeatures.groupby('session_id').mean()\n",
    "#we clustered on session id, so y lets us add the labels by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Cluster'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOne = y[y['Cluster'] == 0]\n",
    "userTwo = y[y['Cluster'] == 1]\n",
    "userThree = y[y['Cluster'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures = userOne.merge(nonModifiedFeatures, on = 'session_id', how = 'inner')\n",
    "userTwoFeatures = userTwo.merge(nonModifiedFeatures, on = 'session_id', how = 'inner')\n",
    "userThreeFeatures = userThree.merge(nonModifiedFeatures, on = 'session_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "userOneFeatures['not_skipped'] = userOneFeatures['not_skipped'].apply(lambda x: 1 if x == True else 0)\n",
    "userTwoFeatures['not_skipped'] = userTwoFeatures['not_skipped'].apply(lambda x: 1 if x == True else 0)\n",
    "userThreeFeatures['not_skipped'] = userThreeFeatures['not_skipped'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures['premium']= userOneFeatures['premium'].apply(lambda x: 1 if x is True else 0)\n",
    "userOneFeatures['hist_user_behavior_is_shuffle'] = userOneFeatures['hist_user_behavior_is_shuffle'].apply(lambda x: 1 if x is True else 0)\n",
    "\n",
    "userTwoFeatures['premium']= userTwoFeatures['premium'].apply(lambda x: 1 if x is True else 0)\n",
    "userTwoFeatures['hist_user_behavior_is_shuffle'] = userTwoFeatures['hist_user_behavior_is_shuffle'].apply(lambda x: 1 if x is True else 0)\n",
    "\n",
    "userThreeFeatures['premium']= userThreeFeatures['premium'].apply(lambda x: 1 if x is True else 0)\n",
    "userThreeFeatures['hist_user_behavior_is_shuffle'] = userThreeFeatures['hist_user_behavior_is_shuffle'].apply(lambda x: 1 if x is True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures.drop(['acousticness_x', 'beat_strength_x', 'bounciness_x',\n",
    "       'danceability_x', 'dyn_range_mean_x', 'energy_x', 'flatness_x',\n",
    "       'instrumentalness_x', 'key_x', 'liveness_x', 'loudness_x',\n",
    "       'mechanism_x', 'mode_x', 'organism_x', 'speechiness_x', 'tempo_x',\n",
    "       'time_signature_x', 'valence_x', 'acoustic_vector_0_x',\n",
    "       'acoustic_vector_1_x', 'acoustic_vector_2_x', 'acoustic_vector_3_x',\n",
    "       'acoustic_vector_4_x', 'acoustic_vector_5_x', 'acoustic_vector_6_x',\n",
    "       'acoustic_vector_7_x', 'Cluster', 'session_position', 'session_length', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hour_of_day', 'premium', 'context_type',\n",
    "       'hist_user_behavior_reason_start', 'duration', 'release_year',\n",
    "       'us_popularity_estimate'], axis = 1, inplace = True)\n",
    "userTwoFeatures.drop(['acousticness_x', 'beat_strength_x', 'bounciness_x',\n",
    "       'danceability_x', 'dyn_range_mean_x', 'energy_x', 'flatness_x',\n",
    "       'instrumentalness_x', 'key_x', 'liveness_x', 'loudness_x',\n",
    "       'mechanism_x', 'mode_x', 'organism_x', 'speechiness_x', 'tempo_x',\n",
    "       'time_signature_x', 'valence_x', 'acoustic_vector_0_x',\n",
    "       'acoustic_vector_1_x', 'acoustic_vector_2_x', 'acoustic_vector_3_x',\n",
    "       'acoustic_vector_4_x', 'acoustic_vector_5_x', 'acoustic_vector_6_x',\n",
    "       'acoustic_vector_7_x', 'Cluster', 'session_position', 'session_length', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hour_of_day', 'premium', 'context_type',\n",
    "       'hist_user_behavior_reason_start', 'duration', 'release_year',\n",
    "       'us_popularity_estimate'], axis = 1, inplace = True)\n",
    "userThreeFeatures.drop(['acousticness_x', 'beat_strength_x', 'bounciness_x',\n",
    "       'danceability_x', 'dyn_range_mean_x', 'energy_x', 'flatness_x',\n",
    "       'instrumentalness_x', 'key_x', 'liveness_x', 'loudness_x',\n",
    "       'mechanism_x', 'mode_x', 'organism_x', 'speechiness_x', 'tempo_x',\n",
    "       'time_signature_x', 'valence_x', 'acoustic_vector_0_x',\n",
    "       'acoustic_vector_1_x', 'acoustic_vector_2_x', 'acoustic_vector_3_x',\n",
    "       'acoustic_vector_4_x', 'acoustic_vector_5_x', 'acoustic_vector_6_x',\n",
    "       'acoustic_vector_7_x', 'Cluster', 'session_position', 'session_length', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hour_of_day', 'premium', 'context_type',\n",
    "       'hist_user_behavior_reason_start', 'duration', 'release_year',\n",
    "       'us_popularity_estimate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures.rename(columns = lambda x: x[:-2] if x[-2:] == '_y' else x, inplace = True)\n",
    "userTwoFeatures.rename(columns = lambda x: x[:-2] if x[-2:] == '_y' else x, inplace = True)\n",
    "userThreeFeatures.rename(columns = lambda x: x[:-2] if x[-2:] == '_y' else x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures.drop(['track_id_clean', \n",
    "         'skip_1', \n",
    "         'skip_2', \n",
    "         'skip_3',\n",
    "         'hist_user_behavior_reason_end',\n",
    "         'track_id',\n",
    "         'date'], \n",
    "        axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTwoFeatures.drop(['track_id_clean', \n",
    "         'skip_1', \n",
    "         'skip_2', \n",
    "         'skip_3',\n",
    "         'hist_user_behavior_reason_end',\n",
    "         'track_id',\n",
    "         'date'], \n",
    "        axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "userThreeFeatures.drop(['track_id_clean', \n",
    "         'skip_1', \n",
    "         'skip_2', \n",
    "         'skip_3',\n",
    "         'hist_user_behavior_reason_end',\n",
    "         'track_id',\n",
    "         'date'], \n",
    "        axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures.drop(['acoustic_vector_0',\n",
    " 'acoustic_vector_1',\n",
    " 'acoustic_vector_2',\n",
    " 'acoustic_vector_3',\n",
    " 'acoustic_vector_4',\n",
    " 'acoustic_vector_5',\n",
    " 'acoustic_vector_6',\n",
    " 'acoustic_vector_7',\n",
    " 'beat_strength',\n",
    " 'bounciness',\n",
    " 'dyn_range_mean',\n",
    " 'flatness',\n",
    " 'mechanism',\n",
    " 'organism'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTwoFeatures.drop(['acoustic_vector_0',\n",
    " 'acoustic_vector_1',\n",
    " 'acoustic_vector_2',\n",
    " 'acoustic_vector_3',\n",
    " 'acoustic_vector_4',\n",
    " 'acoustic_vector_5',\n",
    " 'acoustic_vector_6',\n",
    " 'acoustic_vector_7',\n",
    " 'beat_strength',\n",
    " 'bounciness',\n",
    " 'dyn_range_mean',\n",
    " 'flatness',\n",
    " 'mechanism',\n",
    " 'organism'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "userThreeFeatures.drop(['acoustic_vector_0',\n",
    " 'acoustic_vector_1',\n",
    " 'acoustic_vector_2',\n",
    " 'acoustic_vector_3',\n",
    " 'acoustic_vector_4',\n",
    " 'acoustic_vector_5',\n",
    " 'acoustic_vector_6',\n",
    " 'acoustic_vector_7',\n",
    " 'beat_strength',\n",
    " 'bounciness',\n",
    " 'dyn_range_mean',\n",
    " 'flatness',\n",
    " 'mechanism',\n",
    " 'organism'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "userOneFeatures['mode'] = userOneFeatures['mode'].apply(lambda x: 1 if x == 'major' else 0)\n",
    "userTwoFeatures['mode'] = userTwoFeatures['mode'].apply(lambda x: 1 if x == 'major' else 0)\n",
    "userThreeFeatures['mode'] = userThreeFeatures['mode'].apply(lambda x: 1 if x == 'major' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotifyAPI import Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client ID:\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "Client Secret:\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "s = Spotify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = s.get_playlist_features('Top 50 - USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from spotifyAPI import Spotify\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "class songRecommender():\n",
    "\n",
    "    data = {}\n",
    "    features = []\n",
    "    predictFeatures = []\n",
    "\n",
    "    def __init__(self, data, predict):\n",
    "        '''\n",
    "        data - our persona user's information\n",
    "        predict - the new songs from the API\n",
    "        '''\n",
    "        \n",
    "        self.data = self.parseData(self.dataPreprocessing(data))\n",
    "        #parse the new data\n",
    "        self.features = self.featureVector(self.data) \n",
    "        #generate features for the new data\n",
    "        self.predictFeatures = self.featureAPIVector(predict)\n",
    "        self.predictFeatures = self.scaleAPI(self.getPredict())\n",
    "        #clean the api data\n",
    "        \n",
    "    def dataPreprocessing(self, data):\n",
    "        \n",
    "        cols = data.columns\n",
    "        \n",
    "        ss = ['acousticness', 'danceability', 'energy',\n",
    "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature', 'valence']\n",
    "        \n",
    "        as_is = ['session_id']\n",
    "        \n",
    "        preproc = ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('as_is', FunctionTransformer(lambda x: x), as_is),\n",
    "                ('standard_scale', StandardScaler(), ss),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        processed = pd.DataFrame(preproc.fit_transform(data), columns = cols)\n",
    "        return processed\n",
    "    \n",
    "    def scaleAPI(self, data):\n",
    "        p = data\n",
    "\n",
    "        ss = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'key',\n",
    "           'liveness', 'loudness', 'mode', 'speechiness', 'tempo',\n",
    "           'time_signature', 'valence']\n",
    "\n",
    "        preproc = ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('standard_scale', StandardScaler(), ss)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for entry in p:\n",
    "            temp = pd.DataFrame.from_dict(data = entry[1], orient = 'index').T\n",
    "            df = pd.concat([temp, df])\n",
    "        transformed = pd.DataFrame(preproc.fit_transform(df), columns = ss).to_dict(orient = 'records')\n",
    "        transformedPredict = []\n",
    "\n",
    "        for i in range(len(p)):\n",
    "            transformedPredict.append((p[i][0], transformed[i])) \n",
    "\n",
    "        return transformedPredict\n",
    "\n",
    "    def parseData(self, data):\n",
    "\n",
    "        import json\n",
    "\n",
    "        parsed = json.loads(data.to_json(orient = 'records'))\n",
    "        cleaned = {}\n",
    "\n",
    "        for line in parsed:\n",
    "\n",
    "\n",
    "            featuresSet = ['acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "               'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "               'liveness', 'loudness', 'mechanism', 'mode', 'organism', 'speechiness',\n",
    "               'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "               'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "               'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "               'acoustic_vector_7']\n",
    "            #get only user behaviors\n",
    "\n",
    "            featuresDict = {k:v for k,v in line.items() if k in featuresSet}\n",
    "            cleaned[line['session_id']] = featuresDict\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def featureVector(self, data):\n",
    "        #transform our dictionary of song features into a matrix of feature vectors\n",
    "        vector = []\n",
    "\n",
    "        for k in data:\n",
    "            d = dict(sorted(data[k].items()))\n",
    "            vector.append((k, d))\n",
    "\n",
    "        return vector\n",
    "\n",
    "    def featureAPIVector(self, data):\n",
    "        #transform our API features into usable data\n",
    "        vector = []\n",
    "        keep = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
    "        for d in data:\n",
    "            temp = {k:v for k, v in d.items() if k in keep}\n",
    "            temp = dict(sorted(temp.items()))\n",
    "            vector.append((d['uri'],temp))\n",
    "\n",
    "        return vector\n",
    "\n",
    "    def getData(self):\n",
    "        return self.data\n",
    "    \n",
    "    def getFeatures(self):\n",
    "        return self.features\n",
    "    \n",
    "    def getPredict(self):\n",
    "        return self.predictFeatures\n",
    "\n",
    "    def cosine(self, feature, features, N):\n",
    "        '''\n",
    "        feature - a feature vector of tuples, with index 0 being link and 1 being the vector\n",
    "        feature is the song from the API\n",
    "        features - all feature vectors belonging to current persona user\n",
    "        all the songs in our generated user (data)\n",
    "        N - number of similiar songs we want to return\n",
    "        '''\n",
    "        similarities = []\n",
    "\n",
    "        numer = 0\n",
    "        denom1 = 0\n",
    "        denom2 = 0\n",
    "\n",
    "        for featureTwo in features:\n",
    "            sim = 0\n",
    "            numer = sum([a * b for a, b in zip(list(feature[1].values()), list(featureTwo[1].values()))])\n",
    "            denom1 = sum([l ** 2 for l in list(feature[1].values())])\n",
    "            denom2 = sum([l ** 2 for l in list(featureTwo[1].values())])\n",
    "            denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "            if denom == 0:\n",
    "                sim = 0\n",
    "            sim = numer/denom\n",
    "\n",
    "            similarities.append((sim, featureTwo[0]))\n",
    "\n",
    "        similarities.sort(reverse = True)\n",
    "        return similarities[:N]\n",
    "    \n",
    "    def similar(self, X, y):\n",
    "        predictions = []\n",
    "        for feature in X:\n",
    "            entry = {feature[0]:self.cosine(feature, y, 1)}\n",
    "            #figure out why it keeps returning 10 entries\n",
    "            predictions.append(entry)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = songRecommender(data = userOneFeatures, predict = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'spotify:track:00Blm7zeNqgYLPtW6zg8cj': [(0.9253165736736747,\n",
       "    '65_04308840-6345-4fe5-a5f3-631e7c3a0ff5')]},\n",
       " {'spotify:track:0gplL1WMoJ6iYaPgMCL0gX': [(0.9419606161901593,\n",
       "    '48_6f87f333-6bf3-4c4f-86a2-54f63f2dfcfe')]},\n",
       " {'spotify:track:27NovPIUIRrOZoCHxABJwK': [(0.9478417575519787,\n",
       "    '52_48b015ff-bd82-45f3-9548-407271d1cbb2')]},\n",
       " {'spotify:track:4R67rQNSbbsR4TdUVOIdez': [(0.9721407698947252,\n",
       "    '9_6d01c643-1311-4efb-9953-986e23fa3954')]},\n",
       " {'spotify:track:4iN16F8JtVxG2UTzp3avGl': [(0.9375976869649639,\n",
       "    '34_6d6ec1ac-958d-4bd4-9a19-f26ba36162f7')]}]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar(model.getPredict(), model.getFeatures())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #if we wanted to get nearest centroid\n",
    "# from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "# clf = NearestCentroid()\n",
    "# clf.fit(features, userFeatures['session_id'].unique())\n",
    "# clf.centroids_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
